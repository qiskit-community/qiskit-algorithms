<!doctype html>
<html class="no-js" lang="en">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><link rel="index" title="Index" href="../../../genindex.html" /><link rel="search" title="Search" href="../../../search.html" />

    <!-- Generated with Sphinx 7.4.7 and Furo 2024.01.29 -->
        <title>qiskit_algorithms.optimizers.gradient_descent - Qiskit Algorithms 0.4.0</title>
      <link rel="stylesheet" type="text/css" href="../../../_static/styles/furo.css?v=135e06be" />
    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=3ee1c6c6" />
    <link rel="stylesheet" type="text/css" href="../../../_static/styles/qiskit-sphinx-theme.css?v=fe84956c" />
    <link rel="stylesheet" type="text/css" href="../../../_static/styles/qiskit-ecosystem.css?v=745c5aa7" />
    <link rel="stylesheet" type="text/css" href="../../../_static/plot_directive.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../../../_static/styles/furo-extensions.css?v=36a5483c" />
    <link rel="stylesheet" type="text/css" href="../../../_static/nbsphinx-gallery.css?v=26227f6e" />
    
    


<style>
  body {
    --color-code-background: #ffffff;
  --color-code-foreground: black;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
      }
    }
  }
</style><link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin><link href="https://fonts.googleapis.com/css2?family=IBM+Plex+Mono:wght@400;600&family=IBM+Plex+Sans:ital,wght@0,400;0,600;1,400;1,600&display=swap" rel="stylesheet">
<script src="../../../_static/js/web-components/top-nav-bar.js"></script></head>
  <body>
    
    <script>document.body.dataset.theme = "light";</script>
    
<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg id="icon" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32">
      <defs><style>.cls-1{fill:none;}</style></defs>
      <path d="M28,4H4A2,2,0,0,0,2,6V26a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V6A2,2,0,0,0,28,4ZM4,6H20V26H4ZM28,26H22V6h6Z"/>
      <rect id="_Transparent_Rectangle_" data-name="&lt;Transparent Rectangle&gt;" class="cls-1" width="32" height="32"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg id="icon" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32">
      <defs><style>.cls-1{fill:none;}</style></defs>
      <rect x="4" y="6" width="24" height="2"/>
      <rect x="4" y="24" width="24" height="2"/>
      <rect x="4" y="12" width="24" height="2"/>
      <rect x="4" y="18" width="24" height="2"/>
      <rect id="_Transparent_Rectangle_" data-name="&lt;Transparent Rectangle&gt;" class="cls-1" width="32" height="32"/>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg version="1.1" id="icon" xmlns="http://www.w3.org/2000/svg" x="0px" y="0px"
         viewBox="0 0 32 32" style="enable-background:new 0 0 32 32;" xml:space="preserve"><polygon points="22,16 12,26 10.6,24.6 19.2,16 10.6,7.4 12,6 " stroke="currentColor"/>
      <rect id="_x3C_Transparent_Rectangle_x3E_" fill="none" width="32" height="32"/>
    </svg>
  </symbol>
  <symbol id="svg-new-tab" viewBox="0 0 32 32">
    <svg id="icon" xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 32 32">
      <defs>
        <style>
          .cls-1 {
            fill: none;
          }
        </style>
      </defs>
      <path fill="#6929C4" d="M26,28H6a2.0027,2.0027,0,0,1-2-2V6A2.0027,2.0027,0,0,1,6,4H16V6H6V26H26V16h2V26A2.0027,2.0027,0,0,1,26,28Z"/>
      <polygon fill="#6929C4" points="20 2 20 4 26.586 4 18 12.586 19.414 14 28 5.414 28 12 30 12 30 2 20 2"/>
      <rect id="_Transparent_Rectangle_" data-name="&lt;Transparent Rectangle&gt;" class="cls-1" width="32" height="32"/>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-half" viewBox="0 0 24 24">
    <title>Auto light/dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-shadow">
      <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
      <circle cx="12" cy="12" r="9" />
      <path d="M13 12h5" />
      <path d="M13 15h4" />
      <path d="M13 18h1" />
      <path d="M13 9h4" />
      <path d="M13 6h1" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
  <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
  <div class="visually-hidden">Hide table of contents sidebar</div>
</label>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <div class="visually-hidden">Toggle site navigation sidebar</div>
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="../../../index.html"><div class="brand">Qiskit Algorithms 0.4.0</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle">
          <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
          <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon no-toc" for="__toc">
        <div class="visually-hidden">Toggle table of contents sidebar</div>
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><div class="sidebar-brand">
  <a href="https://www.qiskit.org/ecosystem">
    <div class="sidebar-logo-container">
      <img class="sidebar-logo" src="../../../_static/images/ecosystem-logo.svg" alt="Qiskit Ecosystem logo"/>
    </div>
  </a>
  
  <span class="sidebar-brand-text">Qiskit Algorithms 0.4.0</span>
</div><form class="sidebar-search-container" method="get" action="../../../search.html" role="search">
  <input class="sidebar-search" placeholder="Search" name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <ul>
<li class="toctree-l1"><a class="reference internal" href="../../../index.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../getting_started.html">Getting Started</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../apidocs/qiskit_algorithms.html">API References</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" role="switch" type="checkbox"/><label for="toctree-checkbox-1"><div class="visually-hidden">Toggle navigation of API References</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../stubs/qiskit_algorithms.AmplificationProblem.html">AmplificationProblem</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../stubs/qiskit_algorithms.AmplitudeAmplifier.html">AmplitudeAmplifier</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../stubs/qiskit_algorithms.Grover.html">Grover</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../stubs/qiskit_algorithms.GroverResult.html">GroverResult</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../stubs/qiskit_algorithms.AmplitudeEstimator.html">AmplitudeEstimator</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../stubs/qiskit_algorithms.AmplitudeEstimatorResult.html">AmplitudeEstimatorResult</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../stubs/qiskit_algorithms.AmplitudeEstimation.html">AmplitudeEstimation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../stubs/qiskit_algorithms.AmplitudeEstimationResult.html">AmplitudeEstimationResult</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../stubs/qiskit_algorithms.EstimationProblem.html">EstimationProblem</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../stubs/qiskit_algorithms.FasterAmplitudeEstimation.html">FasterAmplitudeEstimation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../stubs/qiskit_algorithms.FasterAmplitudeEstimationResult.html">FasterAmplitudeEstimationResult</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../stubs/qiskit_algorithms.IterativeAmplitudeEstimation.html">IterativeAmplitudeEstimation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../stubs/qiskit_algorithms.IterativeAmplitudeEstimationResult.html">IterativeAmplitudeEstimationResult</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../stubs/qiskit_algorithms.MaximumLikelihoodAmplitudeEstimation.html">MaximumLikelihoodAmplitudeEstimation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../stubs/qiskit_algorithms.MaximumLikelihoodAmplitudeEstimationResult.html">MaximumLikelihoodAmplitudeEstimationResult</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../stubs/qiskit_algorithms.Eigensolver.html">Eigensolver</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../stubs/qiskit_algorithms.EigensolverResult.html">EigensolverResult</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../stubs/qiskit_algorithms.NumPyEigensolver.html">NumPyEigensolver</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../stubs/qiskit_algorithms.NumPyEigensolverResult.html">NumPyEigensolverResult</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../stubs/qiskit_algorithms.VQD.html">VQD</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../stubs/qiskit_algorithms.VQDResult.html">VQDResult</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../apidocs/qiskit_algorithms.gradients.html">Gradients (<code class="xref py py-mod docutils literal notranslate"><span class="pre">qiskit_algorithms.gradients</span></code>)</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" role="switch" type="checkbox"/><label for="toctree-checkbox-2"><div class="visually-hidden">Toggle navigation of Gradients (qiskit_algorithms.gradients)</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_algorithms.gradients.BaseEstimatorGradient.html">BaseEstimatorGradient</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_algorithms.gradients.BaseQGT.html">BaseQGT</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_algorithms.gradients.BaseSamplerGradient.html">BaseSamplerGradient</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_algorithms.gradients.EstimatorGradientResult.html">EstimatorGradientResult</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_algorithms.gradients.SamplerGradientResult.html">SamplerGradientResult</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_algorithms.gradients.QGTResult.html">QGTResult</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_algorithms.gradients.FiniteDiffEstimatorGradient.html">FiniteDiffEstimatorGradient</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_algorithms.gradients.FiniteDiffSamplerGradient.html">FiniteDiffSamplerGradient</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_algorithms.gradients.LinCombEstimatorGradient.html">LinCombEstimatorGradient</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_algorithms.gradients.LinCombSamplerGradient.html">LinCombSamplerGradient</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_algorithms.gradients.LinCombQGT.html">LinCombQGT</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_algorithms.gradients.ParamShiftEstimatorGradient.html">ParamShiftEstimatorGradient</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_algorithms.gradients.ParamShiftSamplerGradient.html">ParamShiftSamplerGradient</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_algorithms.gradients.QFIResult.html">QFIResult</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_algorithms.gradients.QFI.html">QFI</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_algorithms.gradients.ReverseEstimatorGradient.html">ReverseEstimatorGradient</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_algorithms.gradients.ReverseQGT.html">ReverseQGT</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_algorithms.gradients.SPSAEstimatorGradient.html">SPSAEstimatorGradient</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_algorithms.gradients.SPSASamplerGradient.html">SPSASamplerGradient</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../stubs/qiskit_algorithms.MinimumEigensolver.html">MinimumEigensolver</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../stubs/qiskit_algorithms.MinimumEigensolverResult.html">MinimumEigensolverResult</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../stubs/qiskit_algorithms.NumPyMinimumEigensolver.html">NumPyMinimumEigensolver</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../stubs/qiskit_algorithms.NumPyMinimumEigensolverResult.html">NumPyMinimumEigensolverResult</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../stubs/qiskit_algorithms.VQE.html">VQE</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../stubs/qiskit_algorithms.VQEResult.html">VQEResult</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../stubs/qiskit_algorithms.AdaptVQE.html">AdaptVQE</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../stubs/qiskit_algorithms.AdaptVQEResult.html">AdaptVQEResult</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../stubs/qiskit_algorithms.SamplingMinimumEigensolver.html">SamplingMinimumEigensolver</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../stubs/qiskit_algorithms.SamplingMinimumEigensolverResult.html">SamplingMinimumEigensolverResult</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../stubs/qiskit_algorithms.SamplingVQE.html">SamplingVQE</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../stubs/qiskit_algorithms.SamplingVQEResult.html">SamplingVQEResult</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../stubs/qiskit_algorithms.QAOA.html">QAOA</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../apidocs/qiskit_algorithms.optimizers.html">Optimizers (<code class="xref py py-mod docutils literal notranslate"><span class="pre">qiskit_algorithms.optimizers</span></code>)</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" role="switch" type="checkbox"/><label for="toctree-checkbox-3"><div class="visually-hidden">Toggle navigation of Optimizers (qiskit_algorithms.optimizers)</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_algorithms.optimizers.OptimizerResult.html">OptimizerResult</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_algorithms.optimizers.Optimizer.html">Optimizer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_algorithms.optimizers.Minimizer.html">Minimizer</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../stubs/qiskit_algorithms.optimizers.optimizer_utils.html">qiskit_algorithms.optimizers.optimizer_utils</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" role="switch" type="checkbox"/><label for="toctree-checkbox-4"><div class="visually-hidden">Toggle navigation of qiskit_algorithms.optimizers.optimizer_utils</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../stubs/qiskit_algorithms.optimizers.optimizer_utils.LearningRate.html">LearningRate</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_algorithms.optimizers.SteppableOptimizer.html">SteppableOptimizer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_algorithms.optimizers.AskData.html">AskData</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_algorithms.optimizers.TellData.html">TellData</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_algorithms.optimizers.OptimizerState.html">OptimizerState</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_algorithms.optimizers.ADAM.html">ADAM</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_algorithms.optimizers.AQGD.html">AQGD</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_algorithms.optimizers.CG.html">CG</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_algorithms.optimizers.COBYLA.html">COBYLA</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_algorithms.optimizers.L_BFGS_B.html">L_BFGS_B</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_algorithms.optimizers.GSLS.html">GSLS</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_algorithms.optimizers.GradientDescent.html">GradientDescent</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_algorithms.optimizers.GradientDescentState.html">GradientDescentState</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_algorithms.optimizers.NELDER_MEAD.html">NELDER_MEAD</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_algorithms.optimizers.NFT.html">NFT</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_algorithms.optimizers.P_BFGS.html">P_BFGS</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_algorithms.optimizers.POWELL.html">POWELL</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_algorithms.optimizers.SLSQP.html">SLSQP</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_algorithms.optimizers.SPSA.html">SPSA</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_algorithms.optimizers.QNSPSA.html">QNSPSA</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_algorithms.optimizers.TNC.html">TNC</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_algorithms.optimizers.SciPyOptimizer.html">SciPyOptimizer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_algorithms.optimizers.UMDA.html">UMDA</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_algorithms.optimizers.BOBYQA.html">BOBYQA</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_algorithms.optimizers.IMFIL.html">IMFIL</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_algorithms.optimizers.SNOBFIT.html">SNOBFIT</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_algorithms.optimizers.SBPLX.html">SBPLX</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_algorithms.optimizers.CRS.html">CRS</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_algorithms.optimizers.DIRECT_L.html">DIRECT_L</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_algorithms.optimizers.DIRECT_L_RAND.html">DIRECT_L_RAND</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_algorithms.optimizers.ESCH.html">ESCH</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_algorithms.optimizers.ISRES.html">ISRES</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../stubs/qiskit_algorithms.HamiltonianPhaseEstimation.html">HamiltonianPhaseEstimation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../stubs/qiskit_algorithms.HamiltonianPhaseEstimationResult.html">HamiltonianPhaseEstimationResult</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../stubs/qiskit_algorithms.PhaseEstimationScale.html">PhaseEstimationScale</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../stubs/qiskit_algorithms.PhaseEstimation.html">PhaseEstimation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../stubs/qiskit_algorithms.PhaseEstimationResult.html">PhaseEstimationResult</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../stubs/qiskit_algorithms.IterativePhaseEstimation.html">IterativePhaseEstimation</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../apidocs/qiskit_algorithms.state_fidelities.html">State Fidelities (<code class="xref py py-mod docutils literal notranslate"><span class="pre">qiskit_algorithms.state_fidelities</span></code>)</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" role="switch" type="checkbox"/><label for="toctree-checkbox-5"><div class="visually-hidden">Toggle navigation of State Fidelities (qiskit_algorithms.state_fidelities)</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_algorithms.state_fidelities.BaseStateFidelity.html">BaseStateFidelity</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_algorithms.state_fidelities.ComputeUncompute.html">ComputeUncompute</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_algorithms.state_fidelities.StateFidelityResult.html">StateFidelityResult</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../stubs/qiskit_algorithms.RealTimeEvolver.html">RealTimeEvolver</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../stubs/qiskit_algorithms.ImaginaryTimeEvolver.html">ImaginaryTimeEvolver</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../stubs/qiskit_algorithms.TimeEvolutionResult.html">TimeEvolutionResult</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../stubs/qiskit_algorithms.TimeEvolutionProblem.html">TimeEvolutionProblem</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../stubs/qiskit_algorithms.PVQD.html">PVQD</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../stubs/qiskit_algorithms.PVQDResult.html">PVQDResult</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../stubs/qiskit_algorithms.SciPyImaginaryEvolver.html">SciPyImaginaryEvolver</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../stubs/qiskit_algorithms.SciPyRealEvolver.html">SciPyRealEvolver</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../stubs/qiskit_algorithms.TrotterQRTE.html">TrotterQRTE</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../stubs/qiskit_algorithms.VarQITE.html">VarQITE</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../stubs/qiskit_algorithms.VarQRTE.html">VarQRTE</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../stubs/qiskit_algorithms.VarQTEResult.html">VarQTEResult</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../apidocs/qiskit_algorithms.time_evolvers.variational.html">Time Evolvers, Variational (<code class="xref py py-mod docutils literal notranslate"><span class="pre">qiskit_algorithms.time_evolvers.variational</span></code>)</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" role="switch" type="checkbox"/><label for="toctree-checkbox-6"><div class="visually-hidden">Toggle navigation of Time Evolvers, Variational (qiskit_algorithms.time_evolvers.variational)</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_algorithms.time_evolvers.variational.VariationalPrinciple.html">VariationalPrinciple</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_algorithms.time_evolvers.variational.RealVariationalPrinciple.html">RealVariationalPrinciple</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_algorithms.time_evolvers.variational.ImaginaryVariationalPrinciple.html">ImaginaryVariationalPrinciple</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_algorithms.time_evolvers.variational.RealMcLachlanPrinciple.html">RealMcLachlanPrinciple</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_algorithms.time_evolvers.variational.ImaginaryMcLachlanPrinciple.html">ImaginaryMcLachlanPrinciple</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_algorithms.time_evolvers.variational.ForwardEulerSolver.html">ForwardEulerSolver</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../apidocs/qiskit_algorithms.AlgorithmError.html">AlgorithmError</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../stubs/qiskit_algorithms.AlgorithmJob.html">AlgorithmJob</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../apidocs/qiskit_algorithms.utils.algorithm_globals.html">utils.algorithm_globals</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../tutorials/index.html">Tutorials</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" role="switch" type="checkbox"/><label for="toctree-checkbox-7"><div class="visually-hidden">Toggle navigation of Tutorials</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorials/01_algorithms_introduction.html">An Introduction to Algorithms using Qiskit</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorials/02_vqe_advanced_options.html">Advanced VQE Options</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorials/03_vqe_simulation_with_noise.html">VQE with Qiskit Aer Primitives</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorials/04_vqd.html">Variational Quantum Deflation (VQD) Algorithm</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorials/05_qaoa.html">Quantum Approximate Optimization Algorithm</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorials/06_grover.html">Grover’s Algorithm and Amplitude Amplification</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorials/07_grover_examples.html">Grover’s algorithm examples</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorials/10_pvqd.html">Projected Variational Quantum Dynamics</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorials/11_VarQTE.html">Variational Quantum Time Evolution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorials/12_gradients_framework.html">Gradient Framework</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorials/13_trotterQRTE.html">Quantum Real Time Evolution using Trotterization</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../release_notes.html">Release Notes</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/qiskit-community/qiskit-algorithms">GitHub</a></li>
</ul>

</div></div>
      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          <div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle">
              <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
              <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon no-toc" for="__toc">
            <div class="visually-hidden">Toggle table of contents sidebar</div>
            <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
          </label>
        </div>
        <article role="main">
          <h1>Source code for qiskit_algorithms.optimizers.gradient_descent</h1><div class="highlight"><pre>
<span></span><span class="c1"># This code is part of a Qiskit project.</span>
<span class="c1">#</span>
<span class="c1"># (C) Copyright IBM 2021, 2025.</span>
<span class="c1">#</span>
<span class="c1"># This code is licensed under the Apache License, Version 2.0. You may</span>
<span class="c1"># obtain a copy of this license in the LICENSE.txt file in the root directory</span>
<span class="c1"># of this source tree or at http://www.apache.org/licenses/LICENSE-2.0.</span>
<span class="c1">#</span>
<span class="c1"># Any modifications or derivative works of this code must retain this</span>
<span class="c1"># copyright notice, and modified files need to carry a notice indicating</span>
<span class="c1"># that they have been altered from the originals.</span>

<span class="sd">&quot;&quot;&quot;A standard gradient descent optimizer.&quot;&quot;&quot;</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">__future__</span><span class="w"> </span><span class="kn">import</span> <span class="n">annotations</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">collections.abc</span><span class="w"> </span><span class="kn">import</span> <span class="n">Generator</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">dataclasses</span><span class="w"> </span><span class="kn">import</span> <span class="n">dataclass</span><span class="p">,</span> <span class="n">field</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Any</span><span class="p">,</span> <span class="n">Callable</span><span class="p">,</span> <span class="n">SupportsFloat</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">.optimizer</span><span class="w"> </span><span class="kn">import</span> <span class="n">Optimizer</span><span class="p">,</span> <span class="n">OptimizerSupportLevel</span><span class="p">,</span> <span class="n">OptimizerResult</span><span class="p">,</span> <span class="n">POINT</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">.steppable_optimizer</span><span class="w"> </span><span class="kn">import</span> <span class="n">AskData</span><span class="p">,</span> <span class="n">TellData</span><span class="p">,</span> <span class="n">OptimizerState</span><span class="p">,</span> <span class="n">SteppableOptimizer</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">.optimizer_utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">LearningRate</span>

<span class="n">CALLBACK</span> <span class="o">=</span> <span class="n">Callable</span><span class="p">[[</span><span class="nb">int</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="n">SupportsFloat</span><span class="p">],</span> <span class="kc">None</span><span class="p">]</span>


<div class="viewcode-block" id="GradientDescentState">
<a class="viewcode-back" href="../../../stubs/qiskit_algorithms.optimizers.GradientDescentState.html#qiskit_algorithms.optimizers.GradientDescentState">[docs]</a>
<span class="nd">@dataclass</span>
<span class="k">class</span><span class="w"> </span><span class="nc">GradientDescentState</span><span class="p">(</span><span class="n">OptimizerState</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;State of :class:`~.GradientDescent`.</span>

<span class="sd">    Dataclass with all the information of an optimizer plus the learning_rate and the stepsize.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">stepsize</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="kc">None</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Norm of the gradient on the last step.&quot;&quot;&quot;</span>

    <span class="n">learning_rate</span><span class="p">:</span> <span class="n">LearningRate</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span><span class="n">compare</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Learning rate at the current step of the optimization process.</span>

<span class="sd">    It behaves like a generator, (use ``next(learning_rate)`` to get the learning rate for the</span>
<span class="sd">    next step) but it can also return  the current learning rate with ``learning_rate.current``.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># See parent class for a comment on having a custom equals. I needed this</span>
    <span class="c1"># too as it does not appear to use super by default and without this failed</span>
    <span class="c1"># the exact same way. Note it does not include learning rate as that field</span>
    <span class="c1"># is not included in the compare as pre the field decorator.</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__eq__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">:</span> <span class="nb">object</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">other</span><span class="p">,</span> <span class="n">GradientDescentState</span><span class="p">):</span>
            <span class="k">return</span> <span class="bp">NotImplemented</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__eq__</span><span class="p">(</span><span class="n">other</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">stepsize</span> <span class="o">==</span> <span class="n">other</span><span class="o">.</span><span class="n">stepsize</span></div>



<div class="viewcode-block" id="GradientDescent">
<a class="viewcode-back" href="../../../stubs/qiskit_algorithms.optimizers.GradientDescent.html#qiskit_algorithms.optimizers.GradientDescent">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">GradientDescent</span><span class="p">(</span><span class="n">SteppableOptimizer</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;The gradient descent minimization routine.</span>

<span class="sd">    For a function :math:`f` and an initial point :math:`\vec\theta_0`, the standard (or &quot;vanilla&quot;)</span>
<span class="sd">    gradient descent method is an iterative scheme to find the minimum :math:`\vec\theta^*` of</span>
<span class="sd">    :math:`f` by updating the parameters in the direction of the negative gradient of :math:`f`</span>

<span class="sd">    .. math::</span>

<span class="sd">        \vec\theta_{n+1} = \vec\theta_{n} - \eta_n \vec\nabla f(\vec\theta_{n}),</span>

<span class="sd">    for a small learning rate :math:`\eta_n &gt; 0`.</span>

<span class="sd">    You can either provide the analytic gradient :math:`\vec\nabla f` as ``jac``</span>
<span class="sd">    in the :meth:`~.minimize` method, or, if you do not provide it, use a finite difference</span>
<span class="sd">    approximation of the gradient. To adapt the size of the perturbation in the finite difference</span>
<span class="sd">    gradients, set the ``perturbation`` property in the initializer.</span>

<span class="sd">    This optimizer supports a callback function. If provided in the initializer, the optimizer</span>
<span class="sd">    will call the callback in each iteration with the following information in this order:</span>
<span class="sd">    current number of function values, current parameters, current function value, norm of current</span>
<span class="sd">    gradient.</span>

<span class="sd">    Examples:</span>

<span class="sd">        A minimum example that will use finite difference gradients with a default perturbation</span>
<span class="sd">        of 0.01 and a default learning rate of 0.01.</span>

<span class="sd">        .. code-block:: python</span>

<span class="sd">            from qiskit_algorithms.optimizers import GradientDescent</span>

<span class="sd">            def fun(x):</span>
<span class="sd">                return (np.linalg.norm(x) - 1) ** 2</span>

<span class="sd">            initial_point = np.array([1, 0.5, -0.2])</span>

<span class="sd">            optimizer = GradientDescent(maxiter=100)</span>

<span class="sd">            result = optimizer.minimize(fun=fun, x0=initial_point)</span>

<span class="sd">            print(f&quot;Found minimum {result.x} at a value&quot;</span>
<span class="sd">                &quot;of {result.fun} using {result.nfev} evaluations.&quot;)</span>

<span class="sd">        An example where the learning rate is an iterator and we supply the analytic gradient.</span>
<span class="sd">        Note how much faster this convergences (i.e. less ``nfev``) compared to the previous</span>
<span class="sd">        example.</span>

<span class="sd">        .. code-block:: python</span>

<span class="sd">            from qiskit_algorithms.optimizers import GradientDescent</span>

<span class="sd">            def learning_rate():</span>
<span class="sd">                power = 0.6</span>
<span class="sd">                constant_coeff = 0.1</span>
<span class="sd">                def power_law():</span>
<span class="sd">                    n = 0</span>
<span class="sd">                    while True:</span>
<span class="sd">                        yield constant_coeff * (n ** power)</span>
<span class="sd">                        n += 1</span>

<span class="sd">                return power_law()</span>

<span class="sd">            def fun(x):</span>
<span class="sd">                return (np.linalg.norm(x) - 1) ** 2</span>

<span class="sd">            def grad_f(x):</span>
<span class="sd">                return 2 * (np.linalg.norm(x) - 1) * x / np.linalg.norm(x)</span>

<span class="sd">            initial_point = np.array([1, 0.5, -0.2])</span>

<span class="sd">            optimizer = GradientDescent(maxiter=100, learning_rate=learning_rate)</span>
<span class="sd">            result = optimizer.minimize(fun=fun, jac=grad_f, x0=initial_point)</span>

<span class="sd">            print(f&quot;Found minimum {result.x} at a value&quot;</span>
<span class="sd">            &quot;of {result.fun} using {result.nfev} evaluations.&quot;)</span>


<span class="sd">    An other example where the evaluation of the function has a chance of failing. The user, with</span>
<span class="sd">    specific knowledge about his function can catch this errors and handle them before passing the</span>
<span class="sd">    result to the optimizer.</span>

<span class="sd">        .. code-block:: python</span>

<span class="sd">            import random</span>
<span class="sd">            import numpy as np</span>
<span class="sd">            from qiskit_algorithms.optimizers import GradientDescent</span>

<span class="sd">            def objective(x):</span>
<span class="sd">                if random.choice([True, False]):</span>
<span class="sd">                    return None</span>
<span class="sd">                else:</span>
<span class="sd">                    return (np.linalg.norm(x) - 1) ** 2</span>

<span class="sd">            def grad(x):</span>
<span class="sd">                if random.choice([True, False]):</span>
<span class="sd">                    return None</span>
<span class="sd">                else:</span>
<span class="sd">                    return 2 * (np.linalg.norm(x) - 1) * x / np.linalg.norm(x)</span>


<span class="sd">            initial_point = np.random.normal(0, 1, size=(100,))</span>

<span class="sd">            optimizer = GradientDescent(maxiter=20)</span>
<span class="sd">            optimizer.start(x0=initial_point, fun=objective, jac=grad)</span>

<span class="sd">            while optimizer.continue_condition():</span>
<span class="sd">                ask_data = optimizer.ask()</span>
<span class="sd">                evaluated_gradient = None</span>

<span class="sd">                while evaluated_gradient is None:</span>
<span class="sd">                    evaluated_gradient = grad(ask_data.x_center)</span>
<span class="sd">                    optimizer.state.njev += 1</span>

<span class="sd">                optimizer.state.nit += 1</span>

<span class="sd">                tell_data = TellData(eval_jac=evaluated_gradient)</span>
<span class="sd">                optimizer.tell(ask_data=ask_data, tell_data=tell_data)</span>

<span class="sd">            result = optimizer.create_result()</span>

<span class="sd">    Users that aren&#39;t dealing with complicated functions and who are more familiar with step by step</span>
<span class="sd">    optimization algorithms can use the :meth:`~.step` method which wraps the :meth:`~.ask`</span>
<span class="sd">    and :meth:`~.tell` methods. In the same spirit the method :meth:`~.minimize` will optimize the</span>
<span class="sd">    function and return the result.</span>

<span class="sd">    To see other libraries that use this interface one can visit:</span>
<span class="sd">    https://optuna.readthedocs.io/en/stable/tutorial/20_recipes/009_ask_and_tell.html</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># pylint: disable=too-many-positional-arguments</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">maxiter</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span>
        <span class="n">learning_rate</span><span class="p">:</span> <span class="p">(</span>
            <span class="nb">float</span> <span class="o">|</span> <span class="nb">list</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">|</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span> <span class="o">|</span> <span class="n">Callable</span><span class="p">[[],</span> <span class="n">Generator</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">]]</span>
        <span class="p">)</span> <span class="o">=</span> <span class="mf">0.01</span><span class="p">,</span>
        <span class="n">tol</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-7</span><span class="p">,</span>
        <span class="n">callback</span><span class="p">:</span> <span class="n">CALLBACK</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">perturbation</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Args:</span>
<span class="sd">            maxiter: The maximum number of iterations.</span>
<span class="sd">            learning_rate: A constant, list, array or factory of generators yielding learning rates</span>
<span class="sd">                           for the parameter updates. See the docstring for an example.</span>
<span class="sd">            tol: If the norm of the parameter update is smaller than this threshold, the</span>
<span class="sd">                optimizer has converged.</span>
<span class="sd">            perturbation: If no gradient is passed to :meth:`~.minimize` the gradient is</span>
<span class="sd">                approximated with a forward finite difference scheme with ``perturbation``</span>
<span class="sd">                perturbation in both directions (defaults to 1e-2 if required).</span>
<span class="sd">                Ignored when we have an explicit function for the gradient.</span>
<span class="sd">        Raises:</span>
<span class="sd">            ValueError: If ``learning_rate`` is an array and its length is less than ``maxiter``.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">maxiter</span><span class="o">=</span><span class="n">maxiter</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">callback</span> <span class="o">=</span> <span class="n">callback</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_state</span><span class="p">:</span> <span class="n">GradientDescentState</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_perturbation</span> <span class="o">=</span> <span class="n">perturbation</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_tol</span> <span class="o">=</span> <span class="n">tol</span>
        <span class="c1"># if learning rate is an array, check it is sufficiently long.</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">learning_rate</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)):</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">learning_rate</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">maxiter</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Length of learning_rate (</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">learning_rate</span><span class="p">)</span><span class="si">}</span><span class="s2">) &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;is smaller than maxiter (</span><span class="si">{</span><span class="n">maxiter</span><span class="si">}</span><span class="s2">).&quot;</span>
                <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="n">learning_rate</span>

    <span class="nd">@property</span>  <span class="c1"># type: ignore[override]</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">state</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">GradientDescentState</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Return the current state of the optimizer.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_state</span>

    <span class="nd">@state</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">:</span> <span class="n">GradientDescentState</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Set the current state of the optimizer.&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_state</span> <span class="o">=</span> <span class="n">state</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">tol</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns the tolerance of the optimizer.</span>

<span class="sd">        Any step with smaller stepsize than this value will stop the optimization.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tol</span>

    <span class="nd">@tol</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">tol</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tol</span><span class="p">:</span> <span class="nb">float</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Set the tolerance.&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_tol</span> <span class="o">=</span> <span class="n">tol</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">perturbation</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span> <span class="o">|</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns the perturbation.</span>

<span class="sd">        This is the perturbation used in the finite difference gradient approximation.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_perturbation</span>

    <span class="nd">@perturbation</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">perturbation</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">perturbation</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Set the perturbation.&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_perturbation</span> <span class="o">=</span> <span class="n">perturbation</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_callback_wrapper</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Wraps the callback function to accommodate GradientDescent.</span>

<span class="sd">        Will call :attr:`~.callback` and pass the following arguments:</span>
<span class="sd">        current number of function values, current parameters, current function value,</span>
<span class="sd">        norm of current gradient.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">callback</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">callback</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">nfev</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">x</span><span class="p">,</span>  <span class="c1"># type: ignore[arg-type]</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">fun</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">x</span><span class="p">),</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">stepsize</span><span class="p">,</span>
            <span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">settings</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
        <span class="c1"># if learning rate or perturbation are custom iterators expand them</span>
        <span class="n">learning_rate</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span>
        <span class="k">if</span> <span class="nb">callable</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span><span class="p">):</span>
            <span class="n">iterator</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span><span class="p">()</span>
            <span class="n">learning_rate</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="nb">next</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">maxiter</span><span class="p">)])</span>

        <span class="k">return</span> <span class="p">{</span>
            <span class="s2">&quot;maxiter&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">maxiter</span><span class="p">,</span>
            <span class="s2">&quot;tol&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">tol</span><span class="p">,</span>
            <span class="s2">&quot;learning_rate&quot;</span><span class="p">:</span> <span class="n">learning_rate</span><span class="p">,</span>
            <span class="s2">&quot;perturbation&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">perturbation</span><span class="p">,</span>
            <span class="s2">&quot;callback&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">callback</span><span class="p">,</span>
        <span class="p">}</span>

<div class="viewcode-block" id="GradientDescent.ask">
<a class="viewcode-back" href="../../../stubs/qiskit_algorithms.optimizers.GradientDescent.html#qiskit_algorithms.optimizers.GradientDescent.ask">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">ask</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">AskData</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns an object with the data needed to evaluate the gradient.</span>

<span class="sd">        If this object contains a gradient function the gradient can be evaluated directly. Otherwise</span>
<span class="sd">        approximate it with a finite difference scheme.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">AskData</span><span class="p">(</span>
            <span class="n">x_jac</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">x</span><span class="p">,</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="GradientDescent.tell">
<a class="viewcode-back" href="../../../stubs/qiskit_algorithms.optimizers.GradientDescent.html#qiskit_algorithms.optimizers.GradientDescent.tell">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">tell</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ask_data</span><span class="p">:</span> <span class="n">AskData</span><span class="p">,</span> <span class="n">tell_data</span><span class="p">:</span> <span class="n">TellData</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Updates :attr:`.~GradientDescentState.x` by an amount proportional to the learning</span>
<span class="sd">        rate and value of the gradient at that point.</span>

<span class="sd">        Args:</span>
<span class="sd">            ask_data: The data used to evaluate the function.</span>
<span class="sd">            tell_data: The data from the function evaluation.</span>

<span class="sd">        Raises:</span>
<span class="sd">            ValueError: If the gradient passed doesn&#39;t have the right dimension.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">x</span><span class="p">)</span> <span class="o">!=</span> <span class="n">np</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">tell_data</span><span class="o">.</span><span class="n">eval_jac</span><span class="p">):</span>  <span class="c1"># type: ignore[arg-type]</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;The gradient does not have the correct dimension&quot;</span><span class="p">)</span>
        <span class="c1"># pylint: disable=attribute-defined-outside-init</span>
        <span class="c1"># Both x and stepsize get flagged as defined outside init since lint 3.2.5</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">x</span> <span class="o">-</span> <span class="nb">next</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">learning_rate</span><span class="p">)</span> <span class="o">*</span> <span class="n">tell_data</span><span class="o">.</span><span class="n">eval_jac</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">stepsize</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">tell_data</span><span class="o">.</span><span class="n">eval_jac</span><span class="p">)</span>  <span class="c1"># type: ignore[arg-type,assignment]</span>
        <span class="c1"># pylint: enable=attribute-defined-outside-init</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">nit</span> <span class="o">+=</span> <span class="mi">1</span></div>


<div class="viewcode-block" id="GradientDescent.evaluate">
<a class="viewcode-back" href="../../../stubs/qiskit_algorithms.optimizers.GradientDescent.html#qiskit_algorithms.optimizers.GradientDescent.evaluate">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">evaluate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ask_data</span><span class="p">:</span> <span class="n">AskData</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TellData</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Evaluates the gradient.</span>

<span class="sd">        It does so either by evaluating an analytic gradient or by approximating it with a</span>
<span class="sd">        finite difference scheme. It will either add ``1`` to the number of gradient evaluations or add</span>
<span class="sd">        ``N+1`` to the number of function evaluations (Where N is the dimension of the gradient).</span>

<span class="sd">        Args:</span>
<span class="sd">            ask_data: It contains the point where the gradient is to be evaluated and the gradient</span>
<span class="sd">                      function or, in its absence, the objective function to perform a finite difference</span>
<span class="sd">                      approximation.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The data containing the gradient evaluation.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">jac</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">eps</span> <span class="o">=</span> <span class="mf">0.01</span> <span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">perturbation</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">)</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">perturbation</span>
            <span class="n">grad</span> <span class="o">=</span> <span class="n">Optimizer</span><span class="o">.</span><span class="n">gradient_num_diff</span><span class="p">(</span>
                <span class="n">x_center</span><span class="o">=</span><span class="n">ask_data</span><span class="o">.</span><span class="n">x_jac</span><span class="p">,</span>
                <span class="n">f</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">fun</span><span class="p">,</span>
                <span class="n">epsilon</span><span class="o">=</span><span class="n">eps</span><span class="p">,</span>
                <span class="n">max_evals_grouped</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_max_evals_grouped</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">nfev</span> <span class="o">+=</span> <span class="mi">1</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="n">ask_data</span><span class="o">.</span><span class="n">x_jac</span><span class="p">)</span>  <span class="c1"># type: ignore[arg-type]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">grad</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">jac</span><span class="p">(</span><span class="n">ask_data</span><span class="o">.</span><span class="n">x_jac</span><span class="p">)</span>  <span class="c1"># type: ignore[arg-type]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">njev</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="k">return</span> <span class="n">TellData</span><span class="p">(</span><span class="n">eval_jac</span><span class="o">=</span><span class="n">grad</span><span class="p">)</span></div>


<div class="viewcode-block" id="GradientDescent.create_result">
<a class="viewcode-back" href="../../../stubs/qiskit_algorithms.optimizers.GradientDescent.html#qiskit_algorithms.optimizers.GradientDescent.create_result">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">create_result</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">OptimizerResult</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Creates a result of the optimization process.</span>

<span class="sd">        This result contains the best point, the best function value, the number of function/gradient</span>
<span class="sd">        evaluations and the number of iterations.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The result of the optimization process.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">OptimizerResult</span><span class="p">()</span>
        <span class="n">result</span><span class="o">.</span><span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">x</span>
        <span class="n">result</span><span class="o">.</span><span class="n">fun</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">fun</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">x</span><span class="p">)</span>
        <span class="n">result</span><span class="o">.</span><span class="n">nfev</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">nfev</span>
        <span class="n">result</span><span class="o">.</span><span class="n">njev</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">njev</span>
        <span class="n">result</span><span class="o">.</span><span class="n">nit</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">nit</span>
        <span class="k">return</span> <span class="n">result</span></div>


<div class="viewcode-block" id="GradientDescent.start">
<a class="viewcode-back" href="../../../stubs/qiskit_algorithms.optimizers.GradientDescent.html#qiskit_algorithms.optimizers.GradientDescent.start">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">start</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">fun</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">POINT</span><span class="p">],</span> <span class="nb">float</span><span class="p">],</span>
        <span class="n">x0</span><span class="p">:</span> <span class="n">POINT</span><span class="p">,</span>
        <span class="n">jac</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">POINT</span><span class="p">],</span> <span class="n">POINT</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">bounds</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">tuple</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">state</span> <span class="o">=</span> <span class="n">GradientDescentState</span><span class="p">(</span>
            <span class="n">fun</span><span class="o">=</span><span class="n">fun</span><span class="p">,</span>
            <span class="n">jac</span><span class="o">=</span><span class="n">jac</span><span class="p">,</span>
            <span class="n">x</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">x0</span><span class="p">),</span>
            <span class="n">nit</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
            <span class="n">nfev</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
            <span class="n">njev</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
            <span class="n">learning_rate</span><span class="o">=</span><span class="n">LearningRate</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span><span class="p">),</span>
            <span class="n">stepsize</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="GradientDescent.continue_condition">
<a class="viewcode-back" href="../../../stubs/qiskit_algorithms.optimizers.GradientDescent.html#qiskit_algorithms.optimizers.GradientDescent.continue_condition">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">continue_condition</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Condition that indicates the optimization process should come to an end.</span>

<span class="sd">        When the stepsize is smaller than the tolerance, the optimization process is considered</span>
<span class="sd">        finished.</span>

<span class="sd">        Returns:</span>
<span class="sd">            ``True`` if the optimization process should continue, ``False`` otherwise.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">stepsize</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">True</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">stepsize</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">tol</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">continue_condition</span><span class="p">()</span></div>


<div class="viewcode-block" id="GradientDescent.get_support_level">
<a class="viewcode-back" href="../../../stubs/qiskit_algorithms.optimizers.GradientDescent.html#qiskit_algorithms.optimizers.GradientDescent.get_support_level">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">get_support_level</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get the support level dictionary.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">{</span>
            <span class="s2">&quot;gradient&quot;</span><span class="p">:</span> <span class="n">OptimizerSupportLevel</span><span class="o">.</span><span class="n">supported</span><span class="p">,</span>
            <span class="s2">&quot;bounds&quot;</span><span class="p">:</span> <span class="n">OptimizerSupportLevel</span><span class="o">.</span><span class="n">ignored</span><span class="p">,</span>
            <span class="s2">&quot;initial_point&quot;</span><span class="p">:</span> <span class="n">OptimizerSupportLevel</span><span class="o">.</span><span class="n">required</span><span class="p">,</span>
        <span class="p">}</span></div>
</div>

</pre></div>
        </article>
      </div>
      <footer>
        <div class="related-pages">
          
          
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; 2017-2025, Qiskit Algorithms Development Team
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            <div class="last-updated">
              Last updated on 2025/09/09</div>
          </div>
          <div class="right-details">
            
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer no-toc">
      
      
      
    </aside>
  </div>
</div><script src="../../../_static/jquery.js?v=5d32c60e"></script>
    <script src="../../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
    <script src="../../../_static/documentation_options.js?v=6c02275b"></script>
    <script src="../../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../../_static/scripts/qiskit-sphinx-theme.js?v=4d77b8ca"></script>
    <script src="../../../_static/design-tabs.js?v=f930bc37"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    </body>
</html>